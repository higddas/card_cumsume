# 카드 내역을 통한 소비 행태 분석 

## 주제 선정 배경

한 카드회사의 1년치 카드 사용 데이터를 토대로 80:20의 법칙(파레토 법칙)이 실제로 적용이 되는지 분석하고자 한다.   

<aside>
💡 **파레토 법칙이란?**

'전체 결과의 80%가 전체 원인의 20%에서 일어나는 현상
 예를 들어, 20%의 고객이 백화점 전체 매출의 80%에 해당하는 만큼 쇼핑하는 현상

</aside>

출처 | 위키백과 ‘파레토 법칙’

# 📃 데이터 개요

✔ Raw Data : 롯데카드 고객의 2021.01.01 ~ 2021.12.31 카드 사용 내역 데이터

# 🔎 작업 과정

### (1) 전처리 : 3개의 Data Set에서 필요한 columns 추출 및 병합

1. 상품 구매 정보 : 
    
    **`cust`(고객번호)**, `rct_no`(영수증번호), `chnl_dv`(채널구분), `cop_c`(제휴사), `br_c`(점포코드), **`pd_c`(상품코드)**, **`de_dt`(구매일자), `de_hr`(구매시간)**, **`buy_am`(구매금액)**, `buy_ct`(구매수량)
    
2. 고객 정보 데이터 : ****
    
    **`cust` (고객번호)**, **`ma_fev_dv`(성별), `ages`(연령대)** ,`zon_hlv`(거주지 분류코드)
    
3. 상품 분류 정보 : ****
    
    **`pd_c` (상품코드)**, `pd_nm` (소분류명), **`clac_hlv_nm` (대분류명)**, `clac_mcls_nm` (중분류명)
    
4. 총 자료 수 : 4,381,743 rows x 7 columns    
    
### (2) EDA

1. **상품 품목 분석**
    - 상품 품목은 총 몇 개인가
        
        ```python
        df_cnt = collections.Counter(list(df.clac_hlv_nm))
        len(df_cnt)
        
        >>60
        ```
        
    - 가장 많이 구매한 품목은 무엇인가
        
        `('과자', 440223), ('채소', 423178), ('대용식', 311966), ('유제품', 284420), ('냉장식품', 266481), ('음료', 250179), ('과일', 231090), ('축산물', 190062), ('주류', 169834), ('테넌트/음식점', 166240)`
        
        
 **2. 가격 분석**

- pandas 프로파일링을 이용한 기본적인 파일 구조 파악
    - 최소값 : 1원 / 최대값 : 6,400만원
    - 중앙값 : 4,000원 / 평균값 : 23,212원
        - *평균값에 비해 중앙값이 낮아 구매금액이 낮은 쪽으로 치중되었다는 것을 알 수 있음*
    - 제1사분위수(25%) : 2,000원 / 제3사분위수(75%) : 9,280원
        - *자료를 4등분 하여 살펴봐도 구매가격이 낮은 쪽에 치중되어 있는 것을 알 수 있음*
    - 사분위범위(IQR) :  7,280원
        - *자료의 가운데 50%가 포함되는 구간의 길이로 이상치에 크게 영향을 받지 않음*


- 사분위수를 기준으로 한 이상치 제거 방법 이용
    - *데이터 표본을 4개의 동일한 부분으로 나눈 값*
    - *전체 데이터를 대상으로 제1사분위, 제3사분위를 제거하였음

- 4분위수를 이용한 이상치 제거 결과
    - *카테고리에 따라 차이는 있지만 일반적으로 20,000원 선 안에서 소비하는 것을 확인할 수 있음*
    - *이상치를 제거한 범위 내에 중앙값이 위치한 것을 확인할 수 있음*
    
    
### (3) 파레토 법칙

 ## ✔과정

(1) 총 고객 수와 `상위 20%`의 고객 수 구하기 

```python
cust_num = df['cust'].nunique() # 총 고객 수 : 26917
cust_num * 0.2  # 상위 20퍼의 고객 수 :5383
```

(2) `전체` 고객별 총 구매금액, `상위 20%` 고객별 총 구매금액 구하기

 **고객별 구매 총 금액** 
df_buy= df.groupby('cust').sum('buy_am')

**전체 고객별 구매 총 금액 (내림차순 정렬)**
df_buy_sum= df_buy.sort_values('buy_am', ascending = False)
df_buy_sum


 **상위 20퍼 고객별 구매 총 금액 (min 4139766, max 386581410)**
df_buy_sum_20p = df_buy_sum.sort_values('buy_am', ascending = False)/n
									.head(round(cust_num*0.2))
df_buy_sum_20p

 **전체 고객 26,917 명에 대한 데이터**

- Min 10
- Max 386,581,410(3억 8658만 1410원)

# 상위 20% 고객 5,383명에 대한 데이터 

- 상위 20%는 4백만원부터 4억 가까이 되는 금액으로 분포 범위가 매우 크다는 것을 알 수 있음.

전체 범위 중 유의미한 그래프 형태가 이루어지는 20M까지 범위를 설정하여 롱테일 법칙의 그래프와 유사한 형태가 그려진다는 결론 도출

### (4) 품목간 연관성 분석(Apriori알고리즘)

## ✔과정

1. [rct_no : 영수증 번호]를 기준으로 한번에 결제한 품목을 딕셔너리로 표현
2. 2개 이상 품목을 구매한 값 추출
3. apriori알고리즘을 사용하여 품목 간 연관성이 높은 제품 파악

# 결론 
- 축산물을 구매할 때, 채소를 구매할 확률이 높음
- 과일을 구매할 때 채소를 구매할 확률이 높음

📌 Trouble Shooting

**문제 1**

- [ ]  `**DtypeWarning**: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.`   
    → read_csv를 사용하여 불러 올 때 ‘low_memory=False’를 추가
    → 전체 열을 먼저 읽은 다음 적절한 유형을 결정한다는 뜻
    
- [ ]  TypeError: Object of type builtin_function_or_method is not JSON serializable
    → fig= px.histogram 함수 안에 range_x=[0, 20000000] 를 추가하는 방식으로 해결 
    
    
### ❗ 소감 및 피드백 

**소감**
- 대용량 데이터를 다룸으로써 이론으로 배운 내용을 활용하며 실습하는데 큰 의미가 있었음
- 실제 구매 데이터를 통해서 경제학의 이론에 근접하게 증명하였을 때

**아쉬운 점** 
- 데이터에 거주지 분류코드가 있어서 지역적 특성도 파악하고 싶었으나 마스킹된 데이터이기 때문에 사용하기 어려웠음.
- 대용량 데이터를 다룸에도 불구하고 좀 더 다양하게 시각화 기법을 활용하지 못한 것에 대한 아쉬움이 있었음. 기법을 사용하는 것 자체보다도 유의미한 지표를 만들어내는 방법론을 생각해내는 것에 더 큰 어려움이 있었음
- 그래프 표현과 분석을 용이하게 하기 위해 상품 코드(1933개)가 아닌 대분류 코드(60개)를 사용한 점이 아쉬움.
    → 특히 연관성 분석에 있어서, 60개의 대분류 코드가 아닌 상품코드를 사용했다면 조금 더 구체적인 결과를 얻을 수 있었을 것
- 연관성 분석 시, 상대적으로 구매 확률이 높은 값들을 제거하고 분석을 했다면 더 흥미로운 인사이트를 발견할 수 있을 것
    - 전체 구매 데이터에서 채소와 과일의 구매량이 상대적으로 높음
        → 채소에 대한 확률이 높아서 다른 규칙들에 영향을 받을 수 있기 때문
